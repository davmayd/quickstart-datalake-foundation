
.Network configuration
[width="100%",cols="16%,11%,73%",options="header",]
|===
|Parameter label (name) |Default value|Description|Existing VPC ID
(`VPCID`)|`**__Requires input__**`|ID of your existing VPC (e.g., vpc-0343606e).|Existing VPC CIDR
(`VPCCIDR`)|`**__Requires input__**`|CIDR block for the VPC.|Existing VPC private subnet 1 ID
(`PrivateSubnet1ID`)|`**__Requires input__**`|ID of the private subnet 1, located in Availability Zone 1 (e.g., subnet-a0246dcd).|Existing VPC private subnet 2 ID
(`PrivateSubnet2ID`)|`**__Requires input__**`|ID of the private subnet 2, located in Availability Zone 2 (e.g., subnet-a0246dcd).|Existing VPC public subnet 1 ID
(`PublicSubnet1ID`)|`**__Requires input__**`|ID of the public subnet 1, located in Availability Zone 1 (e.g., subnet-a0246dcd).|Existing VPC public subnet 2 ID
(`PublicSubnet2ID`)|`**__Requires input__**`|ID of the public subnet 2, located in Availability Zone 2 (e.g., subnet-a0246dcd).|NAT 1 IP address
(`NAT1ElasticIP`)|`**__Requires input__**`|Elastic IP address for the first NAT gateway instance that is allowed access to Amazon ES.|NAT 2 IP address
(`NAT2ElasticIP`)|`**__Requires input__**`|Elastic IP address for the second NAT gateway instance that is allowed access to Amazon ES.
|===
.S3 bucket configuration
[width="100%",cols="16%,11%,73%",options="header",]
|===
|Parameter label (name) |Default value|Description|Submissions bucket name
(`SubmissionsBucketName`)|`datalake-submissions`|Name of the S3 submission bucket. A random string is appended to ensure uniqueness.|Curated Datasets bucket name
(`CuratedDatasetsName`)|`datalake-curated-datasets`|Name of the S3 curated datasets bucket. A random string is appended to ensure uniqueness.|Published Data bucket name
(`PublishedDataName`)|`datalake-published-data`|Name of the S3 published data bucket. A random string is appended to ensure uniqueness.|Regional Lambda bucket name
(`RegionalLambdaBucketName`)|`regional-lambda-bucket`|Name of the S3 Regional lambda bucket. A random string is appended to ensure uniqueness.|Athena query results bucket name
(`AthenaQueryResultsBucketName`)|`datalake-athena-query-results`|Name of the S3 Athena query results bucket. A random string is appended to ensure uniqueness.
|===
.Elasticsearch configuration
[width="100%",cols="16%,11%,73%",options="header",]
|===
|Parameter label (name) |Default value|Description|Remote access CIDR
(`RemoteAccessCIDR`)|`**__Requires input__**`|CIDR IP range that is permitted to connect through SSH into the bastion host instance and access Amazon ES. We recommend that you set this value to a trusted IP range (e.g., you might grant software access to only your corporate network). You can use http://checkip.amazonaws.com/ to check your IP address. This parameter must be in the form x.x.x.x/x (e.g., 96.127.8.12/32, YOUR_IP/32).|Elasticsearch domain name
(`ElasticsearchDomainName`)|`datalake-quickstart`|Elasticsearch domain name. Must start with a lowercase letter and contain only letters, numbers, and hyphens (-).|Elasticsearch instance type
(`ElasticsearchNodeType`)|`r5.large.elasticsearch`|EC2 instance type for the Elasticsearch cluster.|Elasticsearch node count
(`ElasticsearchNodeCount`)|`1`|Number of nodes in the Elasticsearch cluster. For guidance, see the Amazon ES documentation.|Elasticsearch EBS volume type
(`ElasticsearchEBSVolumeType`)|`gp2`|EBS volume type.
|===
.Redshift configuration
[width="100%",cols="16%,11%,73%",options="header",]
|===
|Parameter label (name) |Default value|Description|Enable Redshift
(`EnableRedshift`)|`yes`|Specifies whether Amazon Redshift is provisioned.  Set to no if you don’t want to provision the Amazon Redshift cluster.|Make Redshift publicly accessible
(`MakeRedshiftPubliclyAccessible`)|`yes`|Specifies whether Amazon Redshift is publicly accessible. This only applies if EnableRedshift is set to yes.|Redshift user name
(`RedshiftUsername`)|`datalake`|User name that is associated with the master user account for the Amazon Redshift cluster. The user name must contain fewer than 128 alphanumeric characters or underscores, be lowercase, and begin with a letter.|Redshift password
(`RedshiftPassword`)|`**__Requires input__**`|Password that is associated with the master user account for the Amazon Redshift cluster. The password must contain 8–64 printable ASCII characters, excluding: /, ", \', \ and @. It must contain one uppercase letter, one lowercase letter, and one number.|Redshift number of nodes
(`RedshiftNumberOfNodes`)|`1`|Number of nodes in the Amazon Redshift cluster. If you specify a number that’s greater than 1, the Quick Start launches a multinode cluster.|Redshift node type
(`RedshiftNodeType`)|`dc2.large`|Instance type for the nodes in the Amazon Redshift cluster.|Redshift database name
(`RedshiftDatabaseName`)|`quickstart`|Name of the first database to create when the Amazon Redshift cluster is provisioned.|Redshift database port
(`RedshiftDatabasePort`)|`5439`|Port that Amazon Redshift listens on, which is allowed through the security group.|Redshift data encrypted
(`RedshiftEncrypted`)|`false`|Determines whether the Redshift data is encrypted at rest.|Redshift Ssnapshot retention (in Days)
(`RedshiftSnapshotRetention`)|`1`|Retention period for Redshift snapshots (in days). If this is set to 0, snapshots are disabled.
|===
.Kinesis configuration
[width="100%",cols="16%,11%,73%",options="header",]
|===
|Parameter label (name) |Default value|Description|Kinesis Data Stream name
(`KinesisDataStreamName`)|`streaming-submissions`|Name of the Kinesis Data Stream.|Kinesis Data Stream S3 prefix
(`KinesisDataStreamS3Prefix`)|`streaming-submissions`|S3 key prefix for your streaming data that is stored in the S3 submissions bucket. This prefix can include numbers, lowercase letters, uppercase letters, hyphens (-), and forward slashes (/), but should not start with a forward slash, which is automatically added. Use this parameter to specify the location for the streaming data that you want to load.|Kinesis S3 prefix for error objects
(`KinesisErrorOutputPrefix`)|`**__Requires input__**`|(Optional) S3 prefix for error objects.|Kinesis Data Stream S3 compression format
(`KinesisCompressionFormat`)|`UNCOMPRESSED`|Kinesis stream S3 compression format.
|===
.SageMaker configuration
[width="100%",cols="16%,11%,73%",options="header",]
|===
|Parameter label (name) |Default value|Description|Notebook instance name
(`NotebookInstanceName`)|`NotebookInstanceName`|Name of the Amazon SageMaker notebook instance.|Notebook instance type
(`NotebookInstanceType`)|`ml.t3.large`|EC2 instance type for the data-lake Amazon SageMaker notebook instance.
|===
.AWS Quick Start configuration
[width="100%",cols="16%,11%,73%",options="header",]
|===
|Parameter label (name) |Default value|Description|Quick Start S3 bucket name
(`QSS3BucketName`)|`aws-quickstart`|S3 bucket where the Quick Start templates and scripts are installed. If you decide to customize or extend the Quick Start for your own purposes, use this parameter to specify the S3 bucket name you created for your Quick Start assets. The bucket name can include numbers, lowercase letters, uppercase letters, and hyphens (-), but should not start or end with a hyphen.|Quick Start S3 bucket Region
(`QSS3BucketRegion`)|`us-east-1`|AWS Region where the Quick Start S3 bucket (QSS3BucketName) is hosted. If you use your own bucket, you must specify this value.|Quick Start S3 key prefix
(`QSS3KeyPrefix`)|`quickstart-datalake-foundation/`|S3 key prefix used to simulate a folder for your copy of Quick Start assets. Specify a value if you decide to customize or extend the Quick Start for your own purposes. This prefix can include numbers, lowercase letters, uppercase letters, hyphens, and forward slashes.|Key pair name
(`KeyPairName`)|`**__Requires input__**`|Key pairs allow you to securely connect to your instance after it launches.
|===