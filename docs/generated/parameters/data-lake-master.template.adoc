
.Network configuration
[width="100%",cols="16%,11%,73%",options="header",]
|===
|Parameter label (name) |Default value|Description|Availability Zones
(`AvailabilityZones`)|`**__Requires input__**`|The list of Availability Zones to use for the subnets in the VPC. You must specify two Availability Zones.|VPC definition
(`VPCDefinition`)|`QuickstartDefault`|VPC definition name from the Mappings section of the template. Each definition specifies a VPC configuration, including the number of Availability Zones to be used for the deployment and the CIDR blocks for the VPC, public subnets, and private subnets. You can support multiple VPC configurations by extending the map with additional definitions and choosing the appropriate name. If you don’t want to change the VPC configuration, keep the default setting. For more information, see the Adding VPC Definitions section of the guide.
|===
.S3 bucket configuration
[width="100%",cols="16%,11%,73%",options="header",]
|===
|Parameter label (name) |Default value|Description|Submissions bucket name
(`SubmissionsBucketName`)|`datalake-submissions`|Name of the S3 submission bucket. A random string is appended to ensure uniqueness.|Curated datasets bucket name
(`CuratedDatasetsName`)|`datalake-curated-datasets`|Name of the S3 curated datasets bucket. A random string is appended to ensure uniqueness.|Published data bucket name
(`PublishedDataName`)|`datalake-published-data`|Name of the S3 published data bucket. A random string is appended to ensure uniqueness.|Regional Lambda bucket name
(`RegionalLambdaBucketName`)|`regional-lambda-bucket`|Name of the S3 Regional lambda bucket. A random string is appended to ensure uniqueness.|Athena query results bucket name
(`AthenaQueryResultsBucketName`)|`datalake-athena-query-results`|Name of the S3 Athena query results bucket. A random string is appended to ensure uniqueness.
|===
.Elasticsearch configuration
[width="100%",cols="16%,11%,73%",options="header",]
|===
|Parameter label (name) |Default value|Description|Remote access CIDR
(`RemoteAccessCIDR`)|`**__Requires input__**`|CIDR IP range that is permitted to connect through SSH into the bastion host instance and access Amazon ES. We recommend that you set this value to a trusted IP range (e.g., you might grant software access to only your corporate network). You can use http://checkip.amazonaws.com/  to check your IP address. This parameter must be in the form x.x.x.x/x (e.g., 96.127.8.12/32, YOUR_IP/32).|ElasticsearchDomainName
(`ElasticsearchDomainName`)|`datalake-quickstart`|Elasticsearch domain name. This must start with a lowercase letter and contain only letters, numbers, and hyphens (-).|Elasticsearch node type
(`ElasticsearchNodeType`)|`r5.large.elasticsearch`|EC2 instance type for the Elasticsearch cluster.|Elasticsearch node Count
(`ElasticsearchNodeCount`)|`1`|The number of nodes in the Elasticsearch cluster. For guidance, see the Amazon ES documentation.|Elasticsearch EBS volume type
(`ElasticsearchEBSVolumeType`)|`gp2`|EBS volume type.
|===
.Redshift configuration
[width="100%",cols="16%,11%,73%",options="header",]
|===
|Parameter label (name) |Default value|Description|Enable Redshift
(`EnableRedshift`)|`yes`|Specifies whether Amazon Redshift is provisioned.  Set to no if you don’t want to provision the Amazon Redshift cluster.|Make Redshift publicly accessible
(`MakeRedshiftPubliclyAccessible`)|`yes`|Specifies whether Amazon Redshift is publicly accessible. This only applies if EnableRedshift is set to yes.|Redshift user name
(`RedshiftUsername`)|`datalake`|User name that is associated with the master user account for the Amazon Redshift cluster. The user name must contain fewer than 128 alphanumeric characters or underscores, and must be lowercase and begin with a letter.|Redshift password
(`RedshiftPassword`)|`**__Requires input__**`|Password that is associated with the master user account for the Amazon Redshift cluster. The password must contain 8–64 printable ASCII characters, excluding: /, ", \', \ and @. It must contain one uppercase letter, one lowercase letter, and one number.|Redshift number of nodes
(`RedshiftNumberOfNodes`)|`1`|Number of nodes in the Amazon Redshift cluster. If you specify a number that’s greater than 1, the Quick Start launches a multinode cluster.|Redshift node type
(`RedshiftNodeType`)|`dc2.large`|Instance type for the nodes in the Amazon Redshift cluster.|Redshift database name
(`RedshiftDatabaseName`)|`quickstart`|Name of the first database to create when provisioning the Amazon Redshift cluster.|Redshift database port
(`RedshiftDatabasePort`)|`5439`|Port that Amazon Redshift listens on, which is allowed through the security group.|Redshift data encrypted
(`RedshiftEncrypted`)|`false`|Determines whether the Redshift data is encrypted at rest.|Redshift snapshot retention in days
(`RedshiftSnapshotRetention`)|`1`|Retention period for Redshift snapshots (in days). If it is set to 0, snapshots are disabled.
|===
.Kinesis configuration
[width="100%",cols="16%,11%,73%",options="header",]
|===
|Parameter label (name) |Default value|Description|Kinesis Data Stream name
(`KinesisDataStreamName`)|`streaming-submissions`|Name of the Kinesis Data Stream.|Kinesis Data Stream S3 prefix
(`KinesisDataStreamS3Prefix`)|`streaming-submissions`|S3 key prefix for streaming data that is stored in the S3 submissions bucket. This prefix can include numbers, lowercase letters, uppercase letters, hyphens (-), and forward slashes (/), but it should not start with a forward slash because they are automatically appended. Use this parameter to specify the location of the streaming data you want to load.|Kinesis S3 prefix for error objects
(`KinesisErrorOutputPrefix`)|`**__Blank string__**`|(Optional) S3 prefix for error objects.|Kinesis Data Stream S3 compression format
(`KinesisCompressionFormat`)|`UNCOMPRESSED`|Kinesis stream S3 compression format.
|===
.SageMaker configuration
[width="100%",cols="16%,11%,73%",options="header",]
|===
|Parameter label (name) |Default value|Description|Notebook instance name
(`NotebookInstanceName`)|`NotebookInstanceName`|Name of the Amazon SageMaker notebook instance.|Notebook instance type
(`NotebookInstanceType`)|`ml.t3.large`|EC2 instance type for the data-lake Amazon SageMaker notebook instance.
|===
.AWS Quick Start configuration
[width="100%",cols="16%,11%,73%",options="header",]
|===
|Parameter label (name) |Default value|Description|Quick Start S3 bucket name
(`QSS3BucketName`)|`aws-quickstart`|S3 bucket where the Quick Start templates and scripts are installed. If you decide to customize or extend the Quick Start for your own purposes, use this parameter to specify the S3 bucket name you created for your Quick Start assets. The bucket name can include numbers, lowercase letters, uppercase letters, and hyphens (-), but should not start or end with a hyphen.|Quick Start S3 bucket Region
(`QSS3BucketRegion`)|`us-east-1`|AWS Region where the Quick Start S3 bucket (QSS3BucketName) is hosted. If you use your own bucket, you must specify this value.|Quick Start S3 key prefix
(`QSS3KeyPrefix`)|`quickstart-datalake-foundation/`|S3 key prefix used to simulate a folder for your copy of Quick Start assets. Specify a value if you decide to customize or extend the Quick Start for your own purposes. This prefix can include numbers, lowercase letters, uppercase letters, hyphens (-), and forward slashes (/).|Key pair name
(`KeyPairName`)|`**__Requires input__**`|Key pairs allow you to securely connect to your instance after it launches.
|===